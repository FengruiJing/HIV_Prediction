{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPIckWZHaRQ+61mzaukuhh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FengruiJing/HIV_Prediction/blob/main/COVID_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL51DjTEGYVm"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Jun 21 10:44:08 2023\n",
        "\n",
        "@author: FJING\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/us-counties-2020.csv')\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/us-counties-2021.csv')\n",
        "df3 = pd.read_csv('D:/Data/COVID/Data/Population20172021.csv')\n",
        "df12 = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# 移除包含缺失值或无穷大的行\n",
        "df12 = df12.dropna(subset=['fips'])\n",
        "df12 = df12[~df12['fips'].isin([float('inf'), float('-inf')])]\n",
        "\n",
        "# 将县编号列从浮点数转换为整数\n",
        "df12['fips'] = df12['fips'].astype(int)\n",
        "\n",
        "#merge\n",
        "df = df12.merge(df3[['fips', 'Population']], on='fips', how='left')\n",
        "\n",
        "\n",
        "# 将日期列转换为日期格式\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "\n",
        "# 按照县名和日期进行排序\n",
        "df = df.sort_values(['fips', 'date'])\n",
        "\n",
        "\n",
        "# 计算每天的新增病例数\n",
        "df['new_cases'] = df.groupby('fips')['cases'].diff()\n",
        "\n",
        "\n",
        "#\n",
        "df['new_cases_rates'] = (df['new_cases'] / df['Population']) * 100000\n",
        "\n",
        "df\n",
        "# 对新增病例数进行七天滑动平均 右对齐滑动平均\n",
        "df['7_day_avg'] = df.groupby('fips')['new_cases_rates'].rolling(window=7, center=False).mean().reset_index(level=0, drop=True)\n",
        "df\n",
        "\n",
        "# 添加表示每个日期所在的年份和周的列\n",
        "df['year_week'] = df['date'].dt.isocalendar().year.astype(str) + '_' + df['date'].dt.isocalendar().week.astype(str)\n",
        "\n",
        "111111\n",
        "##筛选December 1, 2020–February 28, 2021 winter outbreak period\n",
        "# 创建一个布尔掩码来筛选日期\n",
        "mask = (df['date'] >= '2020-12-01') & (df['date'] <= '2021-02-28')\n",
        "\n",
        "# 使用掩码来筛选数据\n",
        "filtered_df = df.loc[mask]\n",
        "\n",
        "## 计算每个县每周的累计7_day_avg\n",
        "#df['weekly_total_7_day_avg'] = df.groupby(['fips', 'year_week'])['7_day_avg'].transform('sum')\n",
        "\n",
        "# 计算每个县每周的累计7_day_avg\n",
        "weekly_df = filtered_df.groupby(['fips', 'year_week'])['7_day_avg'].agg('sum').reset_index().rename(columns={'7_day_avg': 'weekly_total_7_day_avg'})\n",
        "\n",
        "# 创建一个布尔掩码，对于每个元素，如果它是﹣数，返回True，否则返回False\n",
        "mask0 = weekly_df['weekly_total_7_day_avg'] < 0\n",
        "\n",
        "weekly_df = weekly_df[~mask0]\n",
        "\n",
        "# 将数据保存为CSV文件\n",
        "weekly_df.to_csv('D:/Data/COVID/Data/WinterweeklyCOVID.csv', index=False)\n",
        "\n",
        "# 获取所有唯一的年-周标识符\n",
        "unique_year_weeks = weekly_df['year_week'].unique()\n",
        "\n",
        "# 对每个唯一的年-周标识符\n",
        "for year_week in unique_year_weeks:\n",
        "    # 选择该周的数据\n",
        "    week_data = weekly_df[weekly_df['year_week'] == year_week]\n",
        "\n",
        "    # 保存为CSV文件，文件名包含年-周标识符\n",
        "    week_data.to_csv(f'D:/Data/COVID/Data/{year_week}_COVID.csv', index=False)\n",
        "\n",
        "111111\n",
        "##筛选July 15–October 31,2021 (SARS-CoV-2 B.1.617.2 [Delta] predominance)\n",
        "# 创建一个布尔掩码来筛选日期2\n",
        "mask2 = (df['date'] >= '2021-07-15') & (df['date'] <= '2021-10-31')\n",
        "\n",
        "# 使用掩码来筛选数据\n",
        "filtered_df2 = df.loc[mask2]\n",
        "\n",
        "# 计算每个县每周的累计7_day_avg\n",
        "weekly_df2 = filtered_df2.groupby(['fips', 'year_week'])['7_day_avg'].agg('sum').reset_index().rename(columns={'7_day_avg': 'weekly_total_7_day_avg'})\n",
        "\n",
        "\n",
        "# 创建一个布尔掩码，对于每个元素，如果它是﹣数，返回True，否则返回False\n",
        "mask00 = weekly_df2['weekly_total_7_day_avg'] < 0\n",
        "\n",
        "weekly_df2 = weekly_df2[~mask00]\n",
        "\n",
        "# 将数据保存为CSV文件\n",
        "weekly_df2.to_csv('D:/Data/COVID/Data/DeltaweeklyCOVID.csv', index=False)\n",
        "\n",
        "\n",
        "# 获取所有唯一的年-周标识符\n",
        "unique_year_weeks = weekly_df2['year_week'].unique()\n",
        "\n",
        "# 对每个唯一的年-周标识符\n",
        "for year_week in unique_year_weeks:\n",
        "    # 选择该周的数据\n",
        "    week_data2 = weekly_df2[weekly_df2['year_week'] == year_week]\n",
        "\n",
        "    # 保存为CSV文件，文件名包含年-周标识符\n",
        "    week_data2.to_csv(f'D:/Data/COVID/Data/{year_week}_COVID.csv', index=False)\n",
        "\n",
        "\n",
        "111111\n",
        "##筛选'2021-03-01 - 2021-07-14 Sprin period\n",
        "\n",
        "# 创建一个布尔掩码来筛选日期2\n",
        "mask2 = (df['date'] >= '2021-03-01') & (df['date'] <= '2021-07-14')\n",
        "\n",
        "\n",
        "# 使用掩码来筛选数据\n",
        "filtered_df2 = df.loc[mask2]\n",
        "\n",
        "# 计算每个县每周的累计7_day_avg\n",
        "weekly_df2 = filtered_df2.groupby(['fips', 'year_week'])['7_day_avg'].agg('sum').reset_index().rename(columns={'7_day_avg': 'weekly_total_7_day_avg'})\n",
        "\n",
        "\n",
        "# 创建一个布尔掩码，对于每个元素，如果它是﹣数，返回True，否则返回False\n",
        "mask00 = weekly_df2['weekly_total_7_day_avg'] < 0\n",
        "\n",
        "weekly_df2 = weekly_df2[~mask00]\n",
        "\n",
        "# 将数据保存为CSV文件\n",
        "weekly_df2.to_csv('D:/Data/COVID/Data/SpringweeklyCOVID.csv', index=False)\n",
        "\n",
        "\n",
        "1111111111111111111\n",
        "1111111111111111111\n",
        "####2023-06-21 calculate ten-year connection indicies\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2020_49_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Winterdata/2020_49_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2020_49_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Winterdata/2020_49_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/cb_2019_us_county_20mProjected1.txt',delimiter='\\t')\n",
        "\n",
        "# split the DataFrame into two separate DataFrames\n",
        "df21 = df2.iloc[:len(df2)//2, :]\n",
        "df22 = df2.iloc[len(df2)//2:, :]\n",
        "# save the two sub-files as separate text files\n",
        "df21.to_csv('D:/Data/COVID/Data/textfile_part1.txt', sep='\\t', index=False)\n",
        "df22.to_csv('D:/Data/COVID/Data/textfile_part2.txt', sep='\\t', index=False)\n",
        "\n",
        "#combine two csv files\n",
        "df221 = pd.read_csv('D:/Data/COVID/Data/textfile_part1.csv')\n",
        "df222 = pd.read_csv('D:/Data/COVID/Data/textfile_part2.csv')\n",
        "combined_df = pd.concat([df221, df222], ignore_index=True)\n",
        "# save the concatenated DataFrame as a single CSV file\n",
        "combined_df.to_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv', index=False)\n",
        "\n",
        "combined_df.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "combined_df.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2020_49_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(combined_df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Winterdata/2020_49_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-50\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2020_50_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Winterdata/2020_50_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2020_50_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Winterdata/2020_50_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2020_50_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Winterdata/2020_50_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "\n",
        "111111-51\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2020_51_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Winterdata/2020_51_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2020_51_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Winterdata/2020_51_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2020_51_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Winterdata/2020_51_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "\n",
        "\n",
        "111111-52\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2020_52_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Winterdata/2020_52_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2020_52_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Winterdata/2020_52_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2020_52_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Winterdata/2020_52_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "111111-53\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2020_53_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Winterdata/2020_53_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2020_53_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Winterdata/2020_53_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2020_53_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Winterdata/2020_53_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "\n",
        "111111-2021-1\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_1_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Winterdata/2021_1_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_1_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Winterdata/2021_1_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_1_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Winterdata/2021_1_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "111111-2021-2\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_2_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Winterdata/2021_2_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_2_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Winterdata/2021_2_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_2_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Winterdata/2021_2_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "\n",
        "111111-2021-3\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_3_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Winterdata/2021_3_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_3_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Winterdata/2021_3_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_3_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Winterdata/2021_3_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-2021-4\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_4_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Winterdata/2021_4_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_4_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Winterdata/2021_4_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_4_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Winterdata/2021_4_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-2021-5\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_5_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Winterdata/2021_5_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_5_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Winterdata/2021_5_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_5_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Winterdata/2021_5_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-2021-6\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_6_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Winterdata/2021_6_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_6_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Winterdata/2021_6_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_6_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Winterdata/2021_6_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-2021-7\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_7_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Winterdata/2021_7_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_7_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Winterdata/2021_7_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_7_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Winterdata/2021_7_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "\n",
        "111111-2021-8\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_8_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Winterdata/2021_8_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_8_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Winterdata/2021_8_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Winterdata/2021_8_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Winterdata/2021_8_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "print(df)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=df.pivot_table(values='scaled_sci', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/totalSCIeachCounty.csv', index=True)\n",
        "\n",
        "\n",
        "#PCI\n",
        "df = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=df.pivot_table(values='pci', index='place_i', aggfunc='sum')\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/totalPCIeachCounty.csv', index=True)\n",
        "\n",
        "111111111111111111111\n",
        "111111111111111111111\n",
        "\n",
        "#combine all docs to a new doc\n",
        "#PCI\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 设置数据的目录路径\n",
        "data_dir = 'D:/Data/COVID/Data/extractPCI'  # 根据你的文件夹路径进行调整\n",
        "# 获取该目录下的所有文件名\n",
        "all_files = os.listdir(data_dir)\n",
        "\n",
        "# 过滤出CSV文件\n",
        "csv_files = [file for file in all_files if file.endswith('.csv')]\n",
        "\n",
        "dataframes = []  # 用于存储每个文件的数据\n",
        "\n",
        "for file in csv_files:\n",
        "    df = pd.read_csv(os.path.join(data_dir, file))  # 使用os.path.join来合并目录路径和文件名\n",
        "    year_week = file.split('_')[0] + '_' + file.split('_')[1]  # 提取年份和周数\n",
        "    df['year_week'] = year_week  # 添加一列表示年份和周数\n",
        "    dataframes.append(df)\n",
        "\n",
        "# 使用concat函数将所有的DataFrame合并成一个\n",
        "combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# 如果需要，你可以重新调整列的顺序\n",
        "combined_df = combined_df[['user_loc', 'year_week', 'W1_PCIHIV']]\n",
        "\n",
        "# 查看结果\n",
        "print(combined_df)\n",
        "\n",
        "\n",
        "#SCI\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 设置数据的目录路径\n",
        "data_dir = 'D:/Data/COVID/Data/extractSCI'  # 根据你的文件夹路径进行调整\n",
        "# 获取该目录下的所有文件名\n",
        "all_files = os.listdir(data_dir)\n",
        "\n",
        "# 过滤出CSV文件\n",
        "csv_files = [file for file in all_files if file.endswith('.csv')]\n",
        "\n",
        "dataframes = []  # 用于存储每个文件的数据\n",
        "\n",
        "for file in csv_files:\n",
        "    df = pd.read_csv(os.path.join(data_dir, file))  # 使用os.path.join来合并目录路径和文件名\n",
        "    year_week = file.split('_')[0] + '_' + file.split('_')[1]  # 提取年份和周数\n",
        "    df['year_week'] = year_week  # 添加一列表示年份和周数\n",
        "    dataframes.append(df)\n",
        "\n",
        "# 使用concat函数将所有的DataFrame合并成一个\n",
        "combined_df1 = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# 如果需要，你可以重新调整列的顺序\n",
        "combined_df1 = combined_df1[['user_loc', 'year_week', 'W1_SCIHIV']]\n",
        "\n",
        "# 查看结果\n",
        "print(combined_df1)\n",
        "\n",
        "#SCI\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 设置数据的目录路径\n",
        "data_dir = 'D:/Data/COVID/Data/extractDIS'  # 根据你的文件夹路径进行调整\n",
        "# 获取该目录下的所有文件名\n",
        "all_files = os.listdir(data_dir)\n",
        "\n",
        "# 过滤出CSV文件\n",
        "csv_files = [file for file in all_files if file.endswith('.csv')]\n",
        "\n",
        "dataframes = []  # 用于存储每个文件的数据\n",
        "\n",
        "for file in csv_files:\n",
        "    df = pd.read_csv(os.path.join(data_dir, file))  # 使用os.path.join来合并目录路径和文件名\n",
        "    year_week = file.split('_')[0] + '_' + file.split('_')[1]  # 提取年份和周数\n",
        "    df['year_week'] = year_week  # 添加一列表示年份和周数\n",
        "    dataframes.append(df)\n",
        "\n",
        "# 使用concat函数将所有的DataFrame合并成一个\n",
        "combined_df2 = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# 如果需要，你可以重新调整列的顺序\n",
        "combined_df2 = combined_df2[['user_loc', 'year_week', 'W1_DistanceHIV']]\n",
        "\n",
        "# 查看结果\n",
        "print(combined_df2)\n",
        "\n",
        "#COVID\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 设置数据的目录路径\n",
        "data_dir = 'D:/Data/COVID/Data/extractCOVID'  # 根据你的文件夹路径进行调整\n",
        "# 获取该目录下的所有文件名\n",
        "all_files = os.listdir(data_dir)\n",
        "\n",
        "# 过滤出CSV文件\n",
        "csv_files = [file for file in all_files if file.endswith('.csv')]\n",
        "\n",
        "dataframes = []  # 用于存储每个文件的数据\n",
        "\n",
        "for file in csv_files:\n",
        "    df = pd.read_csv(os.path.join(data_dir, file))  # 使用os.path.join来合并目录路径和文件名\n",
        "    year_week = file.split('_')[0] + '_' + file.split('_')[1]  # 提取年份和周数\n",
        "    df['year_week'] = year_week  # 添加一列表示年份和周数\n",
        "    dataframes.append(df)\n",
        "\n",
        "# 使用concat函数将所有的DataFrame合并成一个\n",
        "combined_df3 = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# 如果需要，你可以重新调整列的顺序\n",
        "combined_df3 = combined_df3[['fips', 'year_week', 'weekly_total_7_day_avg']]\n",
        "combined_df3.rename(columns={'fips': 'user_loc'}, inplace=True)\n",
        "\n",
        "# 查看结果\n",
        "print(combined_df3)\n",
        "\n",
        "\n",
        "\n",
        "# 将4个数据集合并为一个\n",
        "merged_df = combined_df.merge(combined_df1, on=['user_loc', 'year_week'], how='outer')\n",
        "merged_df = merged_df.merge(combined_df2, on=['user_loc', 'year_week'], how='outer')\n",
        "merged_df = merged_df.merge(combined_df3, on=['user_loc', 'year_week'], how='outer')\n",
        "\n",
        "# 显示合并后的数据集\n",
        "print(merged_df)\n",
        "\n",
        "\n",
        "#SCI\n",
        "sci_df = pd.read_csv('D:/Data/COVID/Data/totalSCIeachCounty.csv')\n",
        "final_df = merged_df.merge(sci_df, on='user_loc', how='outer')\n",
        "\n",
        "#PCI\n",
        "pci_df = pd.read_csv('D:/Data/COVID/Data/totalPCIeachCounty.csv')\n",
        "pci_df.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "final_df = final_df.merge(pci_df, on='user_loc', how='outer')\n",
        "\n",
        "111111111111111\n",
        "import numpy as np\n",
        "final_df.columns\n",
        "# 对需要的列进行对数变换，并将结果存储到新的列中\n",
        "final_df['log_pcicov'] = np.log(final_df['W1_PCIHIV'])\n",
        "final_df['log_scicov'] = np.log(final_df['W1_SCIHIV'])\n",
        "final_df['log_discov'] = np.log(final_df['W1_DistanceHIV'])\n",
        "final_df['log_incidence'] = np.log(final_df['weekly_total_7_day_avg'])\n",
        "final_df['log_pci'] = np.log(final_df['pci'])\n",
        "final_df['log_sci'] = np.log(final_df['scaled_sci'])\n",
        "\n",
        "# 显示DataFrame以检查结果\n",
        "print(final_df)\n",
        "final_df.columns\n",
        "final_df.rename(columns={'user_loc': 'fips'}, inplace=True)\n",
        "final_df.rename(columns={'W1_PCIHIV': 'pcicov'}, inplace=True)\n",
        "final_df.rename(columns={'W1_SCIHIV': 'scicov'}, inplace=True)\n",
        "final_df.rename(columns={'W1_DistanceHIV': 'discov'}, inplace=True)\n",
        "\n",
        "# 删除包含NaN值的行\n",
        "final_df = final_df.dropna()\n",
        "\n",
        "\n",
        "111111111111111#确定每个县是否有13个连续的周的数据\n",
        "# 计算每个县的数据量\n",
        "county_counts = final_df.groupby('fips').size()\n",
        "\n",
        "# 找出数据量不等于13的县的列表\n",
        "counties_to_remove = county_counts[county_counts != 13].index\n",
        "\n",
        "# 只保留数据量等于13的县的数据\n",
        "final_df = final_df[~final_df['fips'].isin(counties_to_remove)]\n",
        "\n",
        "\n",
        "#rural-urban\n",
        "urbanrural = pd.read_csv('D:/Data/COVID/Data/UrbanRural.csv')\n",
        "urbanrural.rename(columns={'FIPS': 'fips'}, inplace=True)\n",
        "final_df = final_df.merge(urbanrural, on='fips', how='outer')\n",
        "# 删除包含NaN值的行\n",
        "final_df = final_df.dropna()\n",
        "final_df.to_csv('D:/Data/COVID/Data/FinalUSdata.csv', index=False)\n",
        "\n",
        "11111111111111111111\n",
        "11111111111111111111#select SouthCarolinaData\n",
        "# 创建一个布尔掩码来筛选fips编号\n",
        "mask = (final_df['fips'] >= 45001) & (final_df['fips'] <= 45091)\n",
        "\n",
        "# 使用掩码来筛选数据\n",
        "filtered_df = final_df.loc[mask]\n",
        "\n",
        "# 显示DataFrame以检查结果\n",
        "print(filtered_df)\n",
        "# 按照 'fips' 和 'year_week' 进行排序\n",
        "sorted_df1 = filtered_df.sort_values(['fips', 'year_week'])\n",
        "\n",
        "# 保存到 CSV 文件\n",
        "sorted_df1.to_csv('D:/Data/COVID/Data/FinalSCdata.csv', index=False)\n",
        "\n",
        "11111111111111111111\n",
        "11111111111111111111#select MetropolitanCoreArea\n",
        "# 创建一个布尔掩码来筛选fips编号\n",
        "mask = (final_df['RUCC_2013']==1)\n",
        "\n",
        "# 使用掩码来筛选数据\n",
        "filtered_df = final_df.loc[mask]\n",
        "\n",
        "# 显示DataFrame以检查结果\n",
        "print(filtered_df)\n",
        "# 按照 'fips' 和 'year_week' 进行排序\n",
        "sorted_df2 = filtered_df.sort_values(['fips', 'year_week'])\n",
        "\n",
        "# 保存到 CSV 文件\n",
        "sorted_df2.to_csv('D:/Data/COVID/Data/FinaldataCoreMetro.csv', index=False)\n",
        "\n",
        "1111111111111111\n",
        "111111111111111111111\n",
        "1111111111111111111111\n",
        "###total dataset\n",
        "final_df = pd.read_csv('D:/Data/COVID/Data/FinalUSdata.csv')\n",
        "# 删除包含NaN值的行\n",
        "final_df.columns\n",
        "final_df = final_df.dropna()\n",
        "final_df = final_df[final_df['weekly_total_7_day_avg'] != 0]\n",
        "\n",
        "111111111111111#确定每个县是否有13个连续的周的数据\n",
        "# 计算每个县的数据量\n",
        "county_counts = final_df.groupby('fips').size()\n",
        "\n",
        "# 找出数据量不等于13的县的列表\n",
        "counties_to_remove = county_counts[county_counts != 13].index\n",
        "\n",
        "# 只保留数据量等于13的县的数据\n",
        "final_df = final_df[~final_df['fips'].isin(counties_to_remove)]\n",
        "\n",
        "# 保存到 CSV 文件\n",
        "final_df.to_csv('D:/Data/COVID/Data/FinaldataUSforRNN.csv', index=False)\n",
        "\n",
        "\n",
        "####test\n",
        "#####COVID SC\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "np.random.seed(1053)\n",
        "tf.random.set_seed(1053)\n",
        "\n",
        "df = pd.read_csv('D:/Data/COVID/Data/FinaldataCoreMetro.csv')\n",
        "df.columns\n",
        "\n",
        "df['fips'] = df['fips'].astype('category')\n",
        "df['year_week'] = df['year_week'].astype(str)\n",
        "\n",
        "all_predictions = []\n",
        "all_maes = []\n",
        "all_mapes = []\n",
        "\n",
        "for fips in df['fips'].unique():\n",
        "    print(f'Processing fips {fips}')\n",
        "\n",
        "    county_df = df[df['fips'] == fips]\n",
        "\n",
        "    train_df = county_df[(county_df['year_week'] >= '2020_49') & (county_df['year_week'] < '2021_8')]\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    train = scaler.fit_transform(train_df[['log_incidence']])\n",
        "\n",
        "    x_train = np.array([train[i-9:i] for i in range(9, len(train))])\n",
        "    y_train = np.array([train[i, 0] for i in range(9, len(train))])\n",
        "\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1)) # 1 because we now have 1 feature\n",
        "\n",
        "    best_mape = float('inf')  # start with a high MAPE\n",
        "    best_predictions = None\n",
        "    best_neurons = None\n",
        "    best_mae = None\n",
        "\n",
        "    # Loop over all possible number of neurons\n",
        "    for neurons in range(10, 51, 10):\n",
        "        tf.keras.backend.clear_session()  # Clear the previous model to free up memory\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(neurons, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "        model.add(LSTM(neurons, return_sequences=False))\n",
        "        model.add(Dense(25))\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "        model.fit(x_train, y_train, batch_size=1, epochs=100, verbose=0)\n",
        "\n",
        "        predictions = []\n",
        "        for year_week in ['2021_5', '2021_6', '2021_7', '2021_8']:\n",
        "            input_data = train[-9:]  # take the last 9 years as input data\n",
        "            input_data = input_data.reshape((1, 9, 1)) # 1 because we now have 1 feature\n",
        "\n",
        "            pred_single = model.predict(input_data)\n",
        "            pred_single_transformed_back = scaler.inverse_transform(pred_single)[0][0].item()\n",
        "\n",
        "            predictions.append((fips, year_week, pred_single_transformed_back))\n",
        "\n",
        "            # If we have the true data for the next year, use it to update the training set\n",
        "            if year_week in train_df['year_week'].values:\n",
        "                next_year_data = train_df.loc[train_df['year_week'] == year_week]['log_incidence'].values\n",
        "                train = np.concatenate((train, next_year_data.reshape(-1, 1)))\n",
        "\n",
        "        true_values = county_df[(county_df['year_week'] >= '2021_5') & (county_df['year_week'] <= '2021_8')]['log_incidence'].values\n",
        "        predicted_values = np.array([pred[2] for pred in predictions])\n",
        "\n",
        "        mae = mean_absolute_error(true_values, predicted_values[-len(true_values):])\n",
        "        mape = mean_absolute_percentage_error(true_values, predicted_values[-len(true_values):])\n",
        "\n",
        "        print(f'For {neurons} neurons: MAE: {mae}, MAPE: {mape}')\n",
        "\n",
        "        if mape < best_mape:\n",
        "            best_mape = mape\n",
        "            best_predictions = predictions\n",
        "            best_neurons = neurons\n",
        "            best_mae = mae\n",
        "\n",
        "    all_predictions.extend(best_predictions)\n",
        "    all_maes.append(best_mae)\n",
        "    all_mapes.append(best_mape)\n",
        "\n",
        "    print(f'Best model for fips {fips} had {best_neurons} neurons with MAE: {best_mae}, MAPE: {best_mape}')\n",
        "\n",
        "average_mae = np.mean(all_maes)\n",
        "average_mape = np.mean(all_mapes)\n",
        "\n",
        "print(f'Average MAE across all counties: {average_mae}')\n",
        "print(f'Average MAPE across all counties: {average_mape}')\n",
        "\n",
        "predictions_df = pd.DataFrame(all_predictions, columns=['fips', 'year_week', 'log_incidence'])\n",
        "predictions_df.to_csv('D:/Data/COVID/Data/FinaldataCoreMetroPredictionBestHIVlog.csv', index=False)\n",
        "\n",
        "\n",
        "####test\n",
        "#####WHOLEUS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "np.random.seed(1053)\n",
        "tf.random.set_seed(1053)\n",
        "\n",
        "df = pd.read_csv('D:/Data/COVID/Data/ResultsofWholeUS/FinaldataUSforRNN.csv')\n",
        "df.columns\n",
        "\n",
        "df['fips'] = df['fips'].astype('category')\n",
        "df['year_week'] = df['year_week'].astype(str)\n",
        "\n",
        "all_predictions = []\n",
        "all_maes = []\n",
        "all_mapes = []\n",
        "\n",
        "for fips in df['fips'].unique():\n",
        "    print(f'Processing fips {fips}')\n",
        "\n",
        "    county_df = df[df['fips'] == fips]\n",
        "\n",
        "    train_df = county_df[(county_df['year_week'] >= '2020_49') & (county_df['year_week'] < '2021_8')]\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    train = scaler.fit_transform(train_df[['log_incidence']])\n",
        "\n",
        "    x_train = np.array([train[i-9:i] for i in range(9, len(train))])\n",
        "    y_train = np.array([train[i, 0] for i in range(9, len(train))])\n",
        "\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1)) # 1 because we now have 1 feature\n",
        "\n",
        "    best_mape = float('inf')  # start with a high MAPE\n",
        "    best_predictions = None\n",
        "    best_neurons = None\n",
        "    best_mae = None\n",
        "\n",
        "    # Loop over all possible number of neurons\n",
        "    for neurons in range(10, 51, 10):\n",
        "        tf.keras.backend.clear_session()  # Clear the previous model to free up memory\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(neurons, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "        model.add(LSTM(neurons, return_sequences=False))\n",
        "        model.add(Dense(25))\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "        model.fit(x_train, y_train, batch_size=1, epochs=100, verbose=0)\n",
        "\n",
        "        predictions = []\n",
        "        for year_week in ['2021_5', '2021_6', '2021_7', '2021_8']:\n",
        "            input_data = train[-9:]  # take the last 9 years as input data\n",
        "            input_data = input_data.reshape((1, 9, 1)) # 1 because we now have 1 feature\n",
        "\n",
        "            pred_single = model.predict(input_data)\n",
        "            pred_single_transformed_back = scaler.inverse_transform(pred_single)[0][0].item()\n",
        "\n",
        "            predictions.append((fips, year_week, pred_single_transformed_back))\n",
        "\n",
        "            # If we have the true data for the next year, use it to update the training set\n",
        "            if year_week in train_df['year_week'].values:\n",
        "                next_year_data = train_df.loc[train_df['year_week'] == year_week]['log_incidence'].values\n",
        "                train = np.concatenate((train, next_year_data.reshape(-1, 1)))\n",
        "\n",
        "        true_values = county_df[(county_df['year_week'] >= '2021_5') & (county_df['year_week'] <= '2021_8')]['log_incidence'].values\n",
        "        predicted_values = np.array([pred[2] for pred in predictions])\n",
        "\n",
        "        mae = mean_absolute_error(true_values, predicted_values[-len(true_values):])\n",
        "        mape = mean_absolute_percentage_error(true_values, predicted_values[-len(true_values):])\n",
        "\n",
        "        print(f'For {neurons} neurons: MAE: {mae}, MAPE: {mape}')\n",
        "\n",
        "        if mape < best_mape:\n",
        "            best_mape = mape\n",
        "            best_predictions = predictions\n",
        "            best_neurons = neurons\n",
        "            best_mae = mae\n",
        "\n",
        "    all_predictions.extend(best_predictions)\n",
        "    all_maes.append(best_mae)\n",
        "    all_mapes.append(best_mape)\n",
        "\n",
        "    print(f'Best model for fips {fips} had {best_neurons} neurons with MAE: {best_mae}, MAPE: {best_mape}')\n",
        "\n",
        "average_mae = np.mean(all_maes)\n",
        "average_mape = np.mean(all_mapes)\n",
        "\n",
        "print(f'Average MAE across all counties: {average_mae}')\n",
        "print(f'Average MAPE across all counties: {average_mape}')\n",
        "\n",
        "predictions_df = pd.DataFrame(all_predictions, columns=['fips', 'year_week', 'log_incidence'])\n",
        "predictions_df.to_csv('D:/Data/COVID/Data/ResultsofWholeUS/USBestCOVlog.csv', index=False)\n",
        "\n",
        "\n",
        "\n",
        "11111111111111111\n",
        "1111111111111111111\n",
        "1111111111111111111111\n",
        "###Spring period calculation\n",
        "\n",
        "import pandas as pd\n",
        "# 将数据保存为CSV文件\n",
        "df = pd.read_csv('D:/Data/COVID/Data/SpringweeklyCOVID.csv')\n",
        "\n",
        "\n",
        "#SCI\n",
        "sci_df = pd.read_csv('D:/Data/COVID/Data/totalSCIeachCounty.csv')\n",
        "sci_df.rename(columns={'user_loc': 'fips'}, inplace=True)\n",
        "\n",
        "final_df = df.merge(sci_df, on='fips', how='outer')\n",
        "\n",
        "#PCI\n",
        "pci_df = pd.read_csv('D:/Data/COVID/Data/totalPCIeachCounty.csv')\n",
        "pci_df.rename(columns={'place_i': 'fips'}, inplace=True)\n",
        "final_df = final_df.merge(pci_df, on='fips', how='outer')\n",
        "final_df.columns\n",
        "\n",
        "#urbanrural\n",
        "UrbanRural_df = pd.read_csv('D:/Data/COVID/Data/UrbanRural.csv')\n",
        "UrbanRural_df.rename(columns={'FIPS': 'fips'}, inplace=True)\n",
        "final_df = final_df.merge(UrbanRural_df, on='fips', how='outer')\n",
        "\n",
        "final_df = final_df.dropna()\n",
        "\n",
        "\n",
        "111111111111111\n",
        "import numpy as np\n",
        "final_df.columns\n",
        "# 对需要的列进行对数变换，并将结果存储到新的列中\n",
        "final_df['log_incidence'] = np.log(final_df['weekly_total_7_day_avg'])\n",
        "final_df['log_pci'] = np.log(final_df['pci'])\n",
        "final_df['log_sci'] = np.log(final_df['scaled_sci'])\n",
        "\n",
        "# 按照 'fips' 和 'year_week' 进行排序\n",
        "final_df = final_df.sort_values(['fips', 'year_week'])\n",
        "\n",
        "# no zero values\n",
        "final_df = final_df.loc[final_df['weekly_total_7_day_avg'] != 0]\n",
        "# no zero values\n",
        "final_df = final_df.loc[final_df['log_incidence'] != 0]\n",
        "\n",
        "\n",
        "111111111111111#确定每个县是否有20个连续的周的数据\n",
        "# 计算每个县的数据量\n",
        "county_counts = final_df.groupby('fips').size()\n",
        "\n",
        "# 找出数据量不等于12的县的列表\n",
        "counties_to_remove = county_counts[county_counts != 20].index\n",
        "\n",
        "# 只保留数据量等于12的县的数据\n",
        "final_df = final_df[~final_df['fips'].isin(counties_to_remove)]\n",
        "\n",
        "\n",
        "# 保存到 CSV 文件\n",
        "final_df.to_csv('D:/Data/COVID/Data/FinaldataHIVdiagnoseUSforRNNSpring.csv', index=False)\n",
        "\n",
        "111111\n",
        "# 创建新列 'year' 和 'week'，并将它们转换为整数，这是因为你的 year_week 列被视为字符串，而不是数字。在字符串排序中，'2021_9' 实际上会出现在 '2021_10' 之后，因为字符串的排序是从左到右，字符接字符地进行的。\n",
        "df = pd.read_csv('D:/Data/COVID/Data/FinaldataHIVdiagnoseUSforRNNSpring.csv')\n",
        "# 创建新列 'year' 和 'week'，并将它们转换为整数\n",
        "df[['year', 'week']] = df['year_week'].str.split('_', expand=True).astype(int)\n",
        "\n",
        "# 然后按照 'year' 和 'week' 列进行排序\n",
        "df.sort_values(['fips', 'year', 'week'], inplace=True)\n",
        "df.to_csv('D:/Data/COVID/Data/FinaldataHIVdiagnoseUSforRNNSpring.csv', index=False)\n",
        "\n",
        "\n",
        "111111111111111111111111111\n",
        "1111111111111111111111\n",
        "###Delta period calculation\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('D:/Data/COVID/Data/DeltaweeklyCOVID.csv')\n",
        "\n",
        "\n",
        "#SCI\n",
        "sci_df = pd.read_csv('D:/Data/COVID/Data/totalSCIeachCounty.csv')\n",
        "sci_df.rename(columns={'user_loc': 'fips'}, inplace=True)\n",
        "\n",
        "final_df = df.merge(sci_df, on='fips', how='outer')\n",
        "\n",
        "#PCI\n",
        "pci_df = pd.read_csv('D:/Data/COVID/Data/totalPCIeachCounty.csv')\n",
        "pci_df.rename(columns={'place_i': 'fips'}, inplace=True)\n",
        "final_df = final_df.merge(pci_df, on='fips', how='outer')\n",
        "final_df.columns\n",
        "\n",
        "#urbanrural\n",
        "UrbanRural_df = pd.read_csv('D:/Data/COVID/Data/UrbanRural.csv')\n",
        "UrbanRural_df.rename(columns={'FIPS': 'fips'}, inplace=True)\n",
        "final_df = final_df.merge(UrbanRural_df, on='fips', how='outer')\n",
        "\n",
        "final_df = final_df.dropna()\n",
        "\n",
        "\n",
        "111111111111111\n",
        "import numpy as np\n",
        "final_df.columns\n",
        "# 对需要的列进行对数变换，并将结果存储到新的列中\n",
        "final_df['log_incidence'] = np.log(final_df['weekly_total_7_day_avg'])\n",
        "final_df['log_pci'] = np.log(final_df['pci'])\n",
        "final_df['log_sci'] = np.log(final_df['scaled_sci'])\n",
        "\n",
        "# 按照 'fips' 和 'year_week' 进行排序\n",
        "final_df = final_df.sort_values(['fips', 'year_week'])\n",
        "\n",
        "# no zero values\n",
        "final_df = final_df.loc[final_df['weekly_total_7_day_avg'] != 0]\n",
        "# no zero values\n",
        "final_df = final_df.loc[final_df['log_incidence'] != 0]\n",
        "\n",
        "\n",
        "111111111111111#确定每个县是否有20个连续的周的数据\n",
        "# 计算每个县的数据量\n",
        "county_counts = final_df.groupby('fips').size()\n",
        "\n",
        "# 找出数据量不等于12的县的列表\n",
        "counties_to_remove = county_counts[county_counts != 16].index\n",
        "\n",
        "# 只保留数据量等于16的县的数据\n",
        "final_df = final_df[~final_df['fips'].isin(counties_to_remove)]\n",
        "\n",
        "\n",
        "# 保存到 CSV 文件\n",
        "final_df.to_csv('D:/Data/COVID/Data/FinaldataHIVdiagnoseUSforRNNDelta.csv', index=False)\n",
        "\n",
        "\n",
        "1111111111111\n",
        "11111111111111\n",
        "#HIV+PCI+SCI totaldataset COVID Delta\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "np.random.seed(1053)\n",
        "tf.random.set_seed(1053)\n",
        "\n",
        "df = pd.read_csv('D:/Data/COVID/Data/FinaldataHIVdiagnoseUSforRNNDelta.csv')\n",
        "\n",
        "df['fips'] = df['fips'].astype('category')\n",
        "df['year_week'] = df['year_week'].astype(str)\n",
        "\n",
        "all_predictions = []\n",
        "all_maes = []\n",
        "all_mapes = []\n",
        "\n",
        "for fips in df['fips'].unique():\n",
        "    print(f'Processing fips {fips}')\n",
        "\n",
        "    county_df = df[df['fips'] == fips]\n",
        "\n",
        "    train_df = county_df[(county_df['year_week'] >= '2021_28') & (county_df['year_week'] < '2021_43')]\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    train = scaler.fit_transform(train_df[['log_incidence', 'log_sci','log_pci']])\n",
        "\n",
        "    x_train = np.array([train[i-9:i] for i in range(9, len(train))])\n",
        "    y_train = np.array([train[i, 0] for i in range(9, len(train))])\n",
        "\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 3)) # 3 because we now have 3 features\n",
        "\n",
        "    best_mape = float('inf')  # start with a high MAPE\n",
        "    best_predictions = None\n",
        "    best_neurons = None\n",
        "    best_mae = None\n",
        "\n",
        "    # Loop over all possible number of neurons\n",
        "    for neurons in range(10, 51, 10):\n",
        "        tf.keras.backend.clear_session()  # Clear the previous model to free up memory\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(neurons, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "        model.add(LSTM(neurons, return_sequences=False))\n",
        "        model.add(Dense(25))\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "        model.fit(x_train, y_train, batch_size=1, epochs=100, verbose=0)\n",
        "\n",
        "        # Rest of the code remains the same\n",
        "        predictions = []\n",
        "        for year_week in ['2021_37', '2021_38', '2021_39', '2021_40','2021_41', '2021_42', '2021_43']:\n",
        "            input_data = train[-9:]  # take the last 9 years as input data\n",
        "            input_data = input_data.reshape((1, 9, 3))\n",
        "\n",
        "            pred_single = model.predict(input_data)\n",
        "            pred_single_transformed_back = scaler.inverse_transform(np.hstack((pred_single, np.full((1, 2), train[-1, 1:]))))[:, 0].item()\n",
        "            # Save prediction instead of replacing with true value\n",
        "            predictions.append((fips, year_week, pred_single_transformed_back))\n",
        "\n",
        "            # If we have the true data for the next year, use it to update the training set\n",
        "            if year_week in train_df['year_week'].values:\n",
        "                next_year_data = train_df.loc[train_df['year_week'] == year_week][['log_incidence', 'log_sci','log_pci']].values\n",
        "                train = np.concatenate((train, next_year_data))\n",
        "\n",
        "        true_values = county_df[(county_df['year_week'] >= '2021_37') & (county_df['year_week'] <= '2021_43')]['log_incidence'].values\n",
        "        predicted_values = np.array([pred[2] for pred in predictions])\n",
        "\n",
        "        mae = mean_absolute_error(true_values, predicted_values[-len(true_values):])\n",
        "        mape = mean_absolute_percentage_error(true_values, predicted_values[-len(true_values):])\n",
        "\n",
        "        print(f'For {neurons} neurons: MAE: {mae}, MAPE: {mape}')\n",
        "\n",
        "        if mape < best_mape:\n",
        "            best_mape = mape\n",
        "            best_predictions = predictions\n",
        "            best_neurons = neurons\n",
        "            best_mae = mae\n",
        "\n",
        "    all_predictions.extend(best_predictions)\n",
        "    all_maes.append(best_mae)\n",
        "    all_mapes.append(best_mape)\n",
        "\n",
        "    print(f'Best model for fips {fips} had {best_neurons} neurons with MAE: {best_mae}, MAPE: {best_mape}')\n",
        "\n",
        "average_mae = np.mean(all_maes)\n",
        "average_mape = np.mean(all_mapes)\n",
        "\n",
        "print(f'Average MAE across all counties: {average_mae}')\n",
        "print(f'Average MAPE across all counties: {average_mape}')\n",
        "\n",
        "predictions_df = pd.DataFrame(all_predictions, columns=['fips', 'year_week', 'Predicted_HIV_Rate'])\n",
        "predictions_df.to_csv('D:/Data/COVID/Data/USBestCOVlogTotalPCIlogTotalSCIlogDelta.csv', index=False)\n",
        "\n",
        "\n",
        "\n",
        "111111111111111111111111111\n",
        "1111111111111111111111\n",
        "###Check use metro data and population density evaluation\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('D:/Data/COVID/Data/FinaldataCoreMetro.csv')\n",
        "\n",
        "\n",
        "#PopulationDensity\n",
        "Pop_df = pd.read_csv('D:/Data/COVID/Data/PopulationDensity.csv')\n",
        "Pop_df.rename(columns={'FIPS': 'fips'}, inplace=True)\n",
        "\n",
        "final_df = df.merge(Pop_df, on='fips', how='outer')\n",
        "\n",
        "\n",
        "111111111111111\n",
        "import numpy as np\n",
        "final_df.columns\n",
        "# 对需要的列进行对数变换，并将结果存储到新的列中\n",
        "final_df['log_PopulationDensity'] = np.log(final_df['PopulationDensity'])\n",
        "\n",
        "\n",
        "# 按照 'fips' 和 'year_week' 进行排序\n",
        "final_df = final_df.sort_values(['fips', 'year_week'])\n",
        "\n",
        "# no zero values\n",
        "final_df = final_df.loc[final_df['log_PopulationDensity'] != 0]\n",
        "# no zero values\n",
        "final_df = final_df.loc[final_df['year_week'] != 0]\n",
        "\n",
        "final_df.dropna(subset=['year_week'], inplace=True)\n",
        "\n",
        "\n",
        "111111111111111#确定每个县是否有20个连续的周的数据\n",
        "# 计算每个县的数据量\n",
        "county_counts = final_df.groupby('fips').size()\n",
        "\n",
        "# 找出数据量不等于12的县的列表\n",
        "counties_to_remove = county_counts[county_counts != 13].index\n",
        "\n",
        "# 只保留数据量等于12的县的数据\n",
        "final_df = final_df[~final_df['fips'].isin(counties_to_remove)]\n",
        "\n",
        "\n",
        "# 保存到 CSV 文件\n",
        "final_df.to_csv('D:/Data/COVID/Data/FinaldataCoreMetroAddPop.csv', index=False)\n",
        "\n",
        "\n",
        "#RNN test\n",
        "###2023-06-30\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "np.random.seed(1053)\n",
        "tf.random.set_seed(1053)\n",
        "\n",
        "df = pd.read_csv('D:/Data/COVID/Data/FinaldataCoreMetroAddPop.csv')\n",
        "\n",
        "df['fips'] = df['fips'].astype('category')\n",
        "df['year_week'] = df['year_week'].astype(str)\n",
        "\n",
        "all_predictions = []\n",
        "all_maes = []\n",
        "all_mapes = []\n",
        "\n",
        "for fips in df['fips'].unique():\n",
        "    print(f'Processing fips {fips}')\n",
        "\n",
        "    county_df = df[df['fips'] == fips]\n",
        "\n",
        "    train_df = county_df[(county_df['year_week'] >= '2020_49') & (county_df['year_week'] < '2021_8')]\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    train = scaler.fit_transform(train_df[['log_incidence', 'log_PopulationDensity']])\n",
        "\n",
        "    x_train = np.array([train[i-9:i] for i in range(9, len(train))])\n",
        "    y_train = np.array([train[i, 0] for i in range(9, len(train))])\n",
        "\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 2)) # 2 because we now have 2 features\n",
        "\n",
        "    best_mape = float('inf')  # start with a high MAPE\n",
        "    best_predictions = None\n",
        "    best_neurons = None\n",
        "    best_mae = None\n",
        "\n",
        "    # Loop over all possible number of neurons\n",
        "    for neurons in range(10, 51, 10):\n",
        "        tf.keras.backend.clear_session()  # Clear the previous model to free up memory\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(neurons, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "        model.add(LSTM(neurons, return_sequences=False))\n",
        "        model.add(Dense(25))\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "        model.fit(x_train, y_train, batch_size=1, epochs=100, verbose=0)\n",
        "\n",
        "        # Rest of the code remains the same\n",
        "        predictions = []\n",
        "        for year_week in ['2021_5', '2021_6', '2021_7', '2021_8']:\n",
        "            input_data = train[-9:]  # take the last 9 years as input data\n",
        "            input_data = input_data.reshape((1, 9, 2))\n",
        "\n",
        "            pred_single = model.predict(input_data)\n",
        "            pred_single_transformed_back = scaler.inverse_transform(np.hstack((pred_single, np.full((1, 1), train[-1, 1]))))[:, 0][0].item()\n",
        "            # Save prediction instead of replacing with true value\n",
        "            predictions.append((fips, year_week, pred_single_transformed_back))\n",
        "\n",
        "            # If we have the true data for the next year, use it to update the training set\n",
        "            if year_week in train_df['year_week'].values:\n",
        "                next_year_data = train_df.loc[train_df['year_week'] == year_week][['log_incidence', 'log_PopulationDensity']].values\n",
        "                train = np.concatenate((train, next_year_data))\n",
        "\n",
        "        true_values = county_df[(county_df['year_week'] >= '2021_5') & (county_df['year_week'] <= '2021_8')]['log_incidence'].values\n",
        "        predicted_values = np.array([pred[2] for pred in predictions])\n",
        "\n",
        "        mae = mean_absolute_error(true_values, predicted_values[-len(true_values):])\n",
        "        mape = mean_absolute_percentage_error(true_values, predicted_values[-len(true_values):])\n",
        "\n",
        "        print(f'For {neurons} neurons: MAE: {mae}, MAPE: {mape}')\n",
        "\n",
        "        if mape < best_mape:\n",
        "            best_mape = mape\n",
        "            best_predictions = predictions\n",
        "            best_neurons = neurons\n",
        "            best_mae = mae\n",
        "\n",
        "    all_predictions.extend(best_predictions)\n",
        "    all_maes.append(best_mae)\n",
        "    all_mapes.append(best_mape)\n",
        "\n",
        "    print(f'Best model for fips {fips} had {best_neurons} neurons with MAE: {best_mae}, MAPE: {best_mape}')\n",
        "\n",
        "average_mae = np.mean(all_maes)\n",
        "average_mape = np.mean(all_mapes)\n",
        "\n",
        "print(f'Average MAE across all counties: {average_mae}')\n",
        "print(f'Average MAPE across all counties: {average_mape}')\n",
        "\n",
        "predictions_df = pd.DataFrame(all_predictions, columns=['fips', 'year_week', 'log_incidence'])\n",
        "predictions_df.to_csv('D:/Data/COVID/Data/MetroCoreResults/USBestCOVloglog_PopulationDensity.csv', index=False)\n",
        "\n",
        "\n",
        "111111111111111111111111111\n",
        "1111111111111111111111\n",
        "###Check use delta  data and population density evaluation\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('D:/Data/COVID/Data/FinaldataHIVdiagnoseUSforRNNDelta.csv')\n",
        "\n",
        "\n",
        "#PopulationDensity\n",
        "Pop_df = pd.read_csv('D:/Data/COVID/Data/PopulationDensity.csv')\n",
        "Pop_df.rename(columns={'FIPS': 'fips'}, inplace=True)\n",
        "\n",
        "final_df = df.merge(Pop_df, on='fips', how='outer')\n",
        "\n",
        "\n",
        "111111111111111\n",
        "import numpy as np\n",
        "final_df.columns\n",
        "# 对需要的列进行对数变换，并将结果存储到新的列中\n",
        "final_df['log_PopulationDensity'] = np.log(final_df['PopulationDensity'])\n",
        "\n",
        "\n",
        "# 按照 'fips' 和 'year_week' 进行排序\n",
        "final_df = final_df.sort_values(['fips', 'year_week'])\n",
        "\n",
        "# no zero values\n",
        "final_df = final_df.loc[final_df['log_PopulationDensity'] != 0]\n",
        "# no zero values\n",
        "final_df = final_df.loc[final_df['year_week'] != 0]\n",
        "\n",
        "final_df.dropna(subset=['year_week'], inplace=True)\n",
        "\n",
        "\n",
        "111111111111111#确定每个县是否有20个连续的周的数据\n",
        "# 计算每个县的数据量\n",
        "county_counts = final_df.groupby('fips').size()\n",
        "\n",
        "# 找出数据量不等于16的县的列表\n",
        "counties_to_remove = county_counts[county_counts != 16].index\n",
        "\n",
        "# 只保留数据量等于12的县的数据\n",
        "final_df = final_df[~final_df['fips'].isin(counties_to_remove)]\n",
        "\n",
        "\n",
        "# 保存到 CSV 文件\n",
        "final_df.to_csv('D:/Data/COVID/Data/FinaldataHIVdiagnoseUSforRNNDeltaPopulation.csv', index=False)\n",
        "\n",
        "\n",
        "\n",
        "111111111111111111111111111\n",
        "1111111111111111111111\n",
        "###Check use winter data and population density evaluation\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('D:/Data/COVID/Data/ResultsofWholeUS/FinaldataUSforRNN.csv')\n",
        "\n",
        "\n",
        "#PopulationDensity\n",
        "Pop_df = pd.read_csv('D:/Data/COVID/Data/PopulationDensity.csv')\n",
        "Pop_df.rename(columns={'FIPS': 'fips'}, inplace=True)\n",
        "\n",
        "final_df = df.merge(Pop_df, on='fips', how='outer')\n",
        "\n",
        "\n",
        "111111111111111\n",
        "import numpy as np\n",
        "final_df.columns\n",
        "# 对需要的列进行对数变换，并将结果存储到新的列中\n",
        "final_df['log_PopulationDensity'] = np.log(final_df['PopulationDensity'])\n",
        "\n",
        "\n",
        "# 按照 'fips' 和 'year_week' 进行排序\n",
        "final_df = final_df.sort_values(['fips', 'year_week'])\n",
        "\n",
        "# no zero values\n",
        "final_df = final_df.loc[final_df['log_PopulationDensity'] != 0]\n",
        "# no zero values\n",
        "final_df = final_df.loc[final_df['year_week'] != 0]\n",
        "\n",
        "final_df.dropna(subset=['year_week'], inplace=True)\n",
        "\n",
        "\n",
        "111111111111111#确定每个县是否有20个连续的周的数据\n",
        "# 计算每个县的数据量\n",
        "county_counts = final_df.groupby('fips').size()\n",
        "\n",
        "# 找出数据量不等于16的县的列表\n",
        "counties_to_remove = county_counts[county_counts != 13].index\n",
        "\n",
        "# 只保留数据量等于12的县的数据\n",
        "final_df = final_df[~final_df['fips'].isin(counties_to_remove)]\n",
        "\n",
        "\n",
        "# 保存到 CSV 文件\n",
        "final_df.to_csv('D:/Data/COVID/Data/ResultsofWholeUS/FinaldataUSforRNNPopulation.csv', index=False)\n",
        "final_df.columns\n",
        "\n",
        "\n",
        "df = pd.read_csv('D:/Data/COVID/Data/ResultsofWholeUS/FinaldataUSforRNN.csv')\n",
        "df.columns\n",
        "\n",
        "final_df=df.dropna(subset=['log_pci'], inplace=True)\n",
        "\n",
        "\n",
        "#COVIDPCINEW\n",
        "###2023-07-03\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "np.random.seed(1053)\n",
        "tf.random.set_seed(1053)\n",
        "\n",
        "df = pd.read_csv('D:/Data/COVID/Data/FinaldataCoreMetroAddPop.csv')\n",
        "\n",
        "df['fips'] = df['fips'].astype('category')\n",
        "df['year_week'] = df['year_week'].astype(str)\n",
        "\n",
        "all_predictions = []\n",
        "all_maes = []\n",
        "all_mapes = []\n",
        "\n",
        "for fips in df['fips'].unique():\n",
        "    print(f'Processing fips {fips}')\n",
        "\n",
        "    county_df = df[df['fips'] == fips]\n",
        "\n",
        "    train_df = county_df[(county_df['year_week'] >= '2020_49') & (county_df['year_week'] < '2021_8')]\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    train = scaler.fit_transform(train_df[['log_pcicov', 'log_incidence']])\n",
        "\n",
        "    x_train = np.array([train[i-9:i, 0] for i in range(9, len(train))])\n",
        "    y_train = np.array([train[i, 1] for i in range(9, len(train))])\n",
        "\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1)) # 1 because we now have 1 features\n",
        "\n",
        "    best_mape = float('inf')  # start with a high MAPE\n",
        "    best_predictions = None\n",
        "    best_neurons = None\n",
        "    best_mae = None\n",
        "\n",
        "    # Loop over all possible number of neurons\n",
        "    for neurons in range(10, 51, 10):\n",
        "        tf.keras.backend.clear_session()  # Clear the previous model to free up memory\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(neurons, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "        model.add(LSTM(neurons, return_sequences=False))\n",
        "        model.add(Dense(25))\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "        model.fit(x_train, y_train, batch_size=1, epochs=100, verbose=0)\n",
        "\n",
        "        # Get the future log_pcicov values for the prediction periods\n",
        "        future_log_pcicov = county_df[county_df['year_week'].isin(['2021_5', '2021_6', '2021_7', '2021_8'])]['log_pcicov'].values\n",
        "\n",
        "        # Initialize an array to hold the prediction inputs\n",
        "        future_inputs = np.empty((0, 9, 1))\n",
        "\n",
        "        # For each prediction period, get the last 9 years of log_pcicov values, including the future ones, and add it to future_inputs\n",
        "        for i in range(4):\n",
        "            last_9_years = np.hstack((train[-(9 - i):, 0], future_log_pcicov[:i+1]))\n",
        "            last_9_years = last_9_years.reshape((1, 9, 1))\n",
        "            future_inputs = np.vstack((future_inputs, last_9_years))\n",
        "\n",
        "        # Use the future log_pcicov values as input to make the predictions\n",
        "        predictions = model.predict(future_inputs)\n",
        "\n",
        "        # Transform the predictions back to the original scale\n",
        "        predictions_transformed_back = [scaler.inverse_transform(np.hstack((future_inputs[i], predictions[i].reshape(-1, 1))))[-1][1] for i in range(4)]\n",
        "\n",
        "        # Prepare the predictions list\n",
        "        predictions = [(fips, year_week, prediction) for year_week, prediction in zip(['2021_5', '2021_6', '2021_7', '2021_8'], predictions_transformed_back)]\n",
        "\n",
        "        true_values = county_df[(county_df['year_week'] >= '2021_5') & (county_df['year_week'] <= '2021_8')]['log_incidence'].values\n",
        "        predicted_values = np.array([pred[2] for pred in predictions])\n",
        "\n",
        "        mae = mean_absolute_error(true_values, predicted_values)\n",
        "        mape = mean_absolute_percentage_error(true_values, predicted_values)\n",
        "\n",
        "        print(f'For {neurons} neurons: MAE: {mae}, MAPE: {mape}')\n",
        "\n",
        "        if mape < best_mape:\n",
        "            best_mape = mape\n",
        "            best_predictions = predictions\n",
        "            best_neurons = neurons\n",
        "            best_mae = mae\n",
        "\n",
        "    all_predictions.extend(best_predictions)\n",
        "    all_maes.append(best_mae)\n",
        "    all_mapes.append(best_mape)\n",
        "\n",
        "    print(f'Best model for fips {fips} had {best_neurons} neurons with MAE: {best_mae}, MAPE: {best_mape}')\n",
        "\n",
        "average_mae = np.mean(all_maes)\n",
        "average_mape = np.mean(all_mapes)\n",
        "\n",
        "print(f'Average MAE across all counties: {average_mae}')\n",
        "print(f'Average MAPE across all counties: {average_mape}')\n",
        "\n",
        "predictions_df = pd.DataFrame(all_predictions, columns=['fips', 'year_week', 'log_incidence'])\n",
        "predictions_df.to_csv('D:/Data/COVID/Data/MetroCoreResults/USBestCOVIDPCINew.csv', index=False)\n",
        "\n",
        "\n",
        "\n",
        "1111111111111111111\n",
        "1111111111111111111\n",
        "####2023-06-21 calculate ten-year connection indicies\n",
        "\n",
        "import pandas as pd\n",
        "weekly_df = pd.read_csv('D:/Data/COVID/Data/FinaldataHIVdiagnoseUSforRNNDelta.csv')\n",
        "unique_year_weeks = weekly_df['year_week'].unique()\n",
        "# 对每个唯一的年-周标识符\n",
        "for year_week in unique_year_weeks:\n",
        "    # 选择该周的数据\n",
        "    week_data = weekly_df[weekly_df['year_week'] == year_week]\n",
        "\n",
        "    # 保存为CSV文件，文件名包含年-周标识符\n",
        "    week_data.to_csv(f'D:/Data/COVID/Data/Delta/{year_week}_COVID.csv', index=False)\n",
        "\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_28_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join.columns\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci_x'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Delta/2021_28_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_28_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci_x'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Delta/2021_28_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/cb_2019_us_county_20mProjected1.txt',delimiter='\\t')\n",
        "\n",
        "# split the DataFrame into two separate DataFrames\n",
        "df21 = df2.iloc[:len(df2)//2, :]\n",
        "df22 = df2.iloc[len(df2)//2:, :]\n",
        "# save the two sub-files as separate text files\n",
        "df21.to_csv('D:/Data/COVID/Data/textfile_part1.txt', sep='\\t', index=False)\n",
        "df22.to_csv('D:/Data/COVID/Data/textfile_part2.txt', sep='\\t', index=False)\n",
        "\n",
        "#combine two csv files\n",
        "df221 = pd.read_csv('D:/Data/COVID/Data/textfile_part1.csv')\n",
        "df222 = pd.read_csv('D:/Data/COVID/Data/textfile_part2.csv')\n",
        "combined_df = pd.concat([df221, df222], ignore_index=True)\n",
        "# save the concatenated DataFrame as a single CSV file\n",
        "combined_df.to_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv', index=False)\n",
        "\n",
        "combined_df.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "combined_df.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_28_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(combined_df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Delta/2021_28_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "\n",
        "111111-29\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_29_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Delta/2021_29_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_29_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Delta/2021_29_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_30_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Delta/2021_29_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "\n",
        "111111-30\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_30_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Delta/2021_30_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_30_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Delta/2021_30_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_30_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Delta/2021_30_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "\n",
        "111111-31\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_31_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Delta/2021_31_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_31_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Delta/2021_31_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_31_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Delta/2021_31_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-32\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_32_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Delta/2021_32_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_32_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Delta/2021_32_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_32_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Delta/2021_32_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-33\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_33_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Delta/2021_33_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_33_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Delta/2021_33_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_33_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Delta/2021_33_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-34\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_34_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Delta/2021_34_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_34_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Delta/2021_34_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_34_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Delta/2021_34_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-35\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_35_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Delta/2021_35_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_35_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Delta/2021_35_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_35_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Delta/2021_35_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-36\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_36_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Delta/2021_36_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_36_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Delta/2021_36_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_36_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Delta/2021_36_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-37\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_37_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Delta/2021_37_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_37_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Delta/2021_37_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_37_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Delta/2021_37_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-38\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_38_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Delta/2021_38_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_38_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Delta/2021_38_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_38_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Delta/2021_38_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-39\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_39_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Delta/2021_39_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_39_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Delta/2021_39_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_39_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Delta/2021_39_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-40\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_40_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Delta/2021_40_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_40_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Delta/2021_40_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_40_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Delta/2021_40_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-41\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_41_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Delta/2021_41_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_41_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Delta/2021_41_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_41_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Delta/2021_41_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-42\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_42_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Delta/2021_42_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_42_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Delta/2021_42_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_42_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Delta/2021_42_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-43\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_43_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Delta/2021_43_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_43_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Delta/2021_43_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_43_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Delta/2021_43_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "111111-1\n",
        "import pandas as pd\n",
        "\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "print(df)\n",
        "# Read HIV file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_28_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join = pd.merge(df,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join['W1_SCIHIV']= inner_join['scaled_sci'] * inner_join['weekly_total_7_day_avg']\n",
        "\n",
        "#show last20 rows\n",
        "last_20_rows = inner_join.tail(20)\n",
        "print(last_20_rows)\n",
        "\n",
        "#pivolt table step\n",
        "pivot_table=inner_join.pivot_table(values='W1_SCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table.to_csv('D:/Data/COVID/Data/Delta/2021_28_COVIDWeightedSCI.csv', index=True)\n",
        "\n",
        "\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "print(df2)\n",
        "# Read HIV 2018 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_28_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join1 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join1\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join1['W1_PCIHIV']= inner_join1['pci'] * inner_join1['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table1=inner_join1.pivot_table(values='W1_PCIHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table1.to_csv('D:/Data/COVID/Data/Delta/2021_28_COVIDWeightedPCI.csv', index=True)\n",
        "\n",
        "\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "# Read HIV 201814 file into DataFrame\n",
        "df1 = pd.read_csv('D:/Data/COVID/Data/Delta/2021_28_COVID.csv')\n",
        "print(df1)\n",
        "\n",
        "# merge two dataframes\n",
        "\n",
        "inner_join2 = pd.merge(df2,\n",
        "\t\t\t\t\tdf1,\n",
        "\t\t\t\t\ton ='fips',\n",
        "\t\t\t\t\thow ='inner')\n",
        "inner_join2\n",
        "\n",
        "\n",
        "# multiply two columns\n",
        "inner_join2['W1_DistanceHIV']= inner_join2['GEOID'] * inner_join2['weekly_total_7_day_avg']\n",
        "\n",
        "#pivolt table step add all together\n",
        "pivot_table2=inner_join2.pivot_table(values='W1_DistanceHIV', index='user_loc', aggfunc='sum')\n",
        "\n",
        "#save the result\n",
        "pivot_table2.to_csv('D:/Data/COVID/Data/Delta/2021_28_COVIDWeightedDIS.csv', index=True)\n",
        "\n",
        "\n",
        "\n",
        "111111111111111111111\n",
        "111111111111111111111\n",
        "\n",
        "#combine all docs to a new doc\n",
        "#PCI\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 设置数据的目录路径\n",
        "data_dir = 'D:/Data/COVID/Data/Delta/extractPCI'  # 根据你的文件夹路径进行调整\n",
        "# 获取该目录下的所有文件名\n",
        "all_files = os.listdir(data_dir)\n",
        "\n",
        "# 过滤出CSV文件\n",
        "csv_files = [file for file in all_files if file.endswith('.csv')]\n",
        "\n",
        "dataframes = []  # 用于存储每个文件的数据\n",
        "\n",
        "for file in csv_files:\n",
        "    df = pd.read_csv(os.path.join(data_dir, file))  # 使用os.path.join来合并目录路径和文件名\n",
        "    year_week = file.split('_')[0] + '_' + file.split('_')[1]  # 提取年份和周数\n",
        "    df['year_week'] = year_week  # 添加一列表示年份和周数\n",
        "    dataframes.append(df)\n",
        "\n",
        "# 使用concat函数将所有的DataFrame合并成一个\n",
        "combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# 如果需要，你可以重新调整列的顺序\n",
        "combined_df = combined_df[['user_loc', 'year_week', 'W1_PCIHIV']]\n",
        "\n",
        "# 查看结果\n",
        "print(combined_df)\n",
        "\n",
        "\n",
        "#SCI\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 设置数据的目录路径\n",
        "data_dir = 'D:/Data/COVID/Data/Delta/extractSCI'  # 根据你的文件夹路径进行调整\n",
        "# 获取该目录下的所有文件名\n",
        "all_files = os.listdir(data_dir)\n",
        "\n",
        "# 过滤出CSV文件\n",
        "csv_files = [file for file in all_files if file.endswith('.csv')]\n",
        "\n",
        "dataframes = []  # 用于存储每个文件的数据\n",
        "\n",
        "for file in csv_files:\n",
        "    df = pd.read_csv(os.path.join(data_dir, file))  # 使用os.path.join来合并目录路径和文件名\n",
        "    year_week = file.split('_')[0] + '_' + file.split('_')[1]  # 提取年份和周数\n",
        "    df['year_week'] = year_week  # 添加一列表示年份和周数\n",
        "    dataframes.append(df)\n",
        "\n",
        "# 使用concat函数将所有的DataFrame合并成一个\n",
        "combined_df1 = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# 如果需要，你可以重新调整列的顺序\n",
        "combined_df1 = combined_df1[['user_loc', 'year_week', 'W1_SCIHIV']]\n",
        "\n",
        "# 查看结果\n",
        "print(combined_df1)\n",
        "\n",
        "#SCI\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 设置数据的目录路径\n",
        "data_dir = 'D:/Data/COVID/Data/Delta/extractDIS'  # 根据你的文件夹路径进行调整\n",
        "# 获取该目录下的所有文件名\n",
        "all_files = os.listdir(data_dir)\n",
        "\n",
        "# 过滤出CSV文件\n",
        "csv_files = [file for file in all_files if file.endswith('.csv')]\n",
        "\n",
        "dataframes = []  # 用于存储每个文件的数据\n",
        "\n",
        "for file in csv_files:\n",
        "    df = pd.read_csv(os.path.join(data_dir, file))  # 使用os.path.join来合并目录路径和文件名\n",
        "    year_week = file.split('_')[0] + '_' + file.split('_')[1]  # 提取年份和周数\n",
        "    df['year_week'] = year_week  # 添加一列表示年份和周数\n",
        "    dataframes.append(df)\n",
        "\n",
        "# 使用concat函数将所有的DataFrame合并成一个\n",
        "combined_df2 = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# 如果需要，你可以重新调整列的顺序\n",
        "combined_df2 = combined_df2[['user_loc', 'year_week', 'W1_DistanceHIV']]\n",
        "\n",
        "# 查看结果\n",
        "print(combined_df2)\n",
        "\n",
        "#COVID\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 设置数据的目录路径\n",
        "data_dir = 'D:/Data/COVID/Data/Delta/extractCOVID'  # 根据你的文件夹路径进行调整\n",
        "# 获取该目录下的所有文件名\n",
        "all_files = os.listdir(data_dir)\n",
        "\n",
        "# 过滤出CSV文件\n",
        "csv_files = [file for file in all_files if file.endswith('.csv')]\n",
        "\n",
        "dataframes = []  # 用于存储每个文件的数据\n",
        "\n",
        "for file in csv_files:\n",
        "    df = pd.read_csv(os.path.join(data_dir, file))  # 使用os.path.join来合并目录路径和文件名\n",
        "    year_week = file.split('_')[0] + '_' + file.split('_')[1]  # 提取年份和周数\n",
        "    df['year_week'] = year_week  # 添加一列表示年份和周数\n",
        "    dataframes.append(df)\n",
        "\n",
        "# 使用concat函数将所有的DataFrame合并成一个\n",
        "combined_df3 = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# 如果需要，你可以重新调整列的顺序\n",
        "combined_df3 = combined_df3[['fips', 'year_week', 'weekly_total_7_day_avg']]\n",
        "combined_df3.rename(columns={'fips': 'user_loc'}, inplace=True)\n",
        "\n",
        "# 查看结果\n",
        "print(combined_df3)\n",
        "\n",
        "\n",
        "\n",
        "# 将4个数据集合并为一个\n",
        "merged_df = combined_df.merge(combined_df1, on=['user_loc', 'year_week'], how='outer')\n",
        "merged_df = merged_df.merge(combined_df2, on=['user_loc', 'year_week'], how='outer')\n",
        "merged_df = merged_df.merge(combined_df3, on=['user_loc', 'year_week'], how='outer')\n",
        "\n",
        "# 显示合并后的数据集\n",
        "print(merged_df)\n",
        "merged_df.columns\n",
        "\n",
        "#SCI\n",
        "sci_df = pd.read_csv('D:/Data/COVID/Data/totalSCIeachCounty.csv')\n",
        "final_df = merged_df.merge(sci_df, on='user_loc', how='outer')\n",
        "\n",
        "#PCI\n",
        "pci_df = pd.read_csv('D:/Data/COVID/Data/totalPCIeachCounty.csv')\n",
        "pci_df.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "final_df = final_df.merge(pci_df, on='user_loc', how='outer')\n",
        "\n",
        "111111111111111\n",
        "import numpy as np\n",
        "final_df.columns\n",
        "# 对需要的列进行对数变换，并将结果存储到新的列中\n",
        "final_df['log_pcicov'] = np.log(final_df['W1_PCIHIV'])\n",
        "final_df['log_scicov'] = np.log(final_df['W1_SCIHIV'])\n",
        "final_df['log_discov'] = np.log(final_df['W1_DistanceHIV'])\n",
        "final_df['log_incidence'] = np.log(final_df['weekly_total_7_day_avg'])\n",
        "final_df['log_pci'] = np.log(final_df['pci'])\n",
        "final_df['log_sci'] = np.log(final_df['scaled_sci'])\n",
        "\n",
        "# 显示DataFrame以检查结果\n",
        "print(final_df)\n",
        "final_df.columns\n",
        "final_df.rename(columns={'user_loc': 'fips'}, inplace=True)\n",
        "final_df.rename(columns={'W1_PCIHIV': 'pcicov'}, inplace=True)\n",
        "final_df.rename(columns={'W1_SCIHIV': 'scicov'}, inplace=True)\n",
        "final_df.rename(columns={'W1_DistanceHIV': 'discov'}, inplace=True)\n",
        "\n",
        "# 删除包含NaN值的行\n",
        "final_df = final_df.dropna()\n",
        "\n",
        "\n",
        "111111111111111#确定每个县是否有13个连续的周的数据\n",
        "# 计算每个县的数据量\n",
        "county_counts = final_df.groupby('fips').size()\n",
        "\n",
        "# 找出数据量不等于13的县的列表\n",
        "counties_to_remove = county_counts[county_counts != 16].index\n",
        "\n",
        "# 只保留数据量等于13的县的数据\n",
        "final_df = final_df[~final_df['fips'].isin(counties_to_remove)]\n",
        "\n",
        "\n",
        "#rural-urban\n",
        "urbanrural = pd.read_csv('D:/Data/COVID/Data/UrbanRural.csv')\n",
        "urbanrural.rename(columns={'FIPS': 'fips'}, inplace=True)\n",
        "final_df = final_df.merge(urbanrural, on='fips', how='outer')\n",
        "# 删除包含NaN值的行\n",
        "final_df = final_df.dropna()\n",
        "final_df.to_csv('D:/Data/COVID/Data/Delta/FinaldataHIVdiagnoseUSforRNNDeltaWeighted.csv', index=False)\n",
        "\n",
        "# 删除包含NaN值的行\n",
        "final_df.columns\n",
        "final_df = final_df.dropna()\n",
        "final_df = final_df[final_df['weekly_total_7_day_avg'] != 0]\n",
        "final_df = final_df[final_df['log_incidence'] != 0]\n",
        "\n",
        "# 保存到 CSV 文件\n",
        "final_df.to_csv('D:/Data/COVID/Data/Delta/FinaldataHIVdiagnoseUSforRNNDeltaWeighted.csv', index=False)\n",
        "\n",
        "\n",
        "11111\n",
        "####Results: mapping parts.\n",
        "1111\n",
        "# Read SCI TSV file into DataFrame\n",
        "df = pd.read_table('D:/Data/COVID/Data/county_county.tsv')\n",
        "df.rename(columns={'fr_loc': 'fips'}, inplace=True)\n",
        "\n",
        "\n",
        "#Manhattan is New York County (ANSI / FIPS 36061)\n",
        "df_selected = df.loc[df['user_loc'] == 36061]\n",
        "print(df_selected)\n",
        "df_selected.to_csv('D:/Data/COVID/Data/FinalResults06302023/NewYorkCountySCI.csv', index=False)\n",
        "\n",
        "#San Francisco, City and County (ANSI / FIPS 06075)\n",
        "df_selected = df.loc[df['user_loc'] == 6075]\n",
        "print(df_selected)\n",
        "df_selected.to_csv('D:/Data/COVID/Data/FinalResults06302023/SanFranCountySCI.csv', index=False)\n",
        "\n",
        "#Richland of South Carolina, FIPS\n",
        "df_selected = df.loc[df['user_loc'] == 45079]\n",
        "print(df_selected)\n",
        "df_selected.to_csv('D:/Data/COVID/Data/FinalResults06302023/RichlandCountySCI.csv', index=False)\n",
        "\n",
        "\n",
        "11111\n",
        "#Calculate PCI\n",
        "# Read PCI 2018 file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/US_County_PCI_2019.csv')\n",
        "df2 = df2.drop(columns=['shared_users', 'place_i_users','place_j_users','dir_pci'])\n",
        "df2.rename(columns={'place_j': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'place_i': 'user_loc'}, inplace=True)\n",
        "\n",
        "\n",
        "#Manhattan is New York County (ANSI / FIPS 36061)\n",
        "df_selected = df2.loc[df2['user_loc'] == 36061]\n",
        "print(df_selected)\n",
        "df_selected.to_csv('D:/Data/COVID/Data/FinalResults06302023/NewYorkCountyPCI.csv', index=False)\n",
        "\n",
        "#San Francisco, City and County (ANSI / FIPS 06075)\n",
        "df_selected = df2.loc[df2['user_loc'] == 6075]\n",
        "print(df_selected)\n",
        "df_selected.to_csv('D:/Data/COVID/Data/FinalResults06302023/SanFranCountyPCI.csv', index=False)\n",
        "\n",
        "#Richland of South Carolina, FIPS\n",
        "df_selected = df2.loc[df2['user_loc'] == 45079]\n",
        "print(df_selected)\n",
        "df_selected.to_csv('D:/Data/COVID/Data/FinalResults06302023/RichlandCountyPCI.csv', index=False)\n",
        "\n",
        "\n",
        "11111\n",
        "#GeoDistanceWeight\n",
        "# Read file into DataFrame\n",
        "df2 = pd.read_csv('D:/Data/COVID/Data/Distancetextfile_part1and2.csv')\n",
        "\n",
        "df2.rename(columns={'cb_2019_us': 'fips'}, inplace=True)\n",
        "df2.rename(columns={'a': 'user_loc'}, inplace=True)\n",
        "\n",
        "\n",
        "#Manhattan is New York County (ANSI / FIPS 36061)\n",
        "df_selected = df2.loc[df2['user_loc'] == 36061]\n",
        "print(df_selected)\n",
        "df_selected.to_csv('D:/Data/COVID/Data/FinalResults06302023/NewYorkCountyDIS.csv', index=False)\n",
        "\n",
        "#San Francisco, City and County (ANSI / FIPS 06075)\n",
        "df_selected = df2.loc[df2['user_loc'] == 6075]\n",
        "print(df_selected)\n",
        "df_selected.to_csv('D:/Data/COVID/Data/FinalResults06302023/SanFranCountyDIS.csv', index=False)\n",
        "\n",
        "#Richland of South Carolina, FIPS\n",
        "df_selected = df2.loc[df2['user_loc'] == 45079]\n",
        "print(df_selected)\n",
        "df_selected.to_csv('D:/Data/COVID/Data/FinalResults06302023/RichlandCountyDIS.csv', index=False)\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 读取CSV文件\n",
        "df = pd.read_csv('D:/Data/COVID/Data/ResultsofWholeUS/FinaldataUSforRNN.csv')\n",
        "df.columns\n",
        "\n",
        "# 预处理数据，将其转换为我们可以更容易操作的格式\n",
        "data = {}\n",
        "for fips in df['fips'].unique():\n",
        "    data[fips] = {\n",
        "        \"COVID incidence\": df[df['fips'] == fips].set_index('year_week')['weekly_total_7_day_avg'].to_dict(),\n",
        "        \"PCIWeightedCOVID\": df[df['fips'] == fips].set_index('year_week')['pcicov'].to_dict(),\n",
        "        \"SCIWeightedCOVID\": df[df['fips'] == fips].set_index('year_week')['scicov'].to_dict(),\n",
        "    }\n",
        "\n",
        "# 预处理数据，将其转换为我们可以更容易操作的格式\n",
        "data = {}\n",
        "for fips in df['fips'].unique():\n",
        "    data[fips] = {\n",
        "        \"COVID incidence\": df[(df['fips'] == fips) & (df['year_week'] <= '2021_8')].set_index('year_week')['weekly_total_7_day_avg'].to_dict(),\n",
        "        \"PCIWeightedCOVID\": df[(df['fips'] == fips) & (df['year_week'] <= '2021_8')].set_index('year_week')['pcicov'].to_dict(),\n",
        "        \"SCIWeightedCOVID\": df[(df['fips'] == fips) & (df['year_week'] <= '2021_8')].set_index('year_week')['scicov'].to_dict(),\n",
        "    }\n",
        "\n",
        "# 定义颜色，将RGB值转化为[0, 1]范围内\n",
        "#colors = [(44/255, 164/255, 44/255), (255/255, 127/255, 14/255), (31/255, 119/255, 180/255)]\n",
        "\n",
        "\n",
        "# 定义年份范围\n",
        "year_week_COVID = list(range(2020_49, 2020_54))\n",
        "year_week_rest = list(range(2020_49, 2020_54))\n",
        "\n",
        "\n",
        "# Create figure with 2x2 layout\n",
        "fig, ax = plt.subplots(2, 2, figsize=(15, 15))\n",
        "\n",
        "# Define thresholds\n",
        "thresholds = [500, 4000000, 10000000000, 800]\n",
        "\n",
        "# Plot each county's HIV prevalence\n",
        "for fips, metrics in data.items():\n",
        "    values = np.array(list(metrics[\"COVID incidence\"].values()))\n",
        "    if np.any(values > thresholds[0]):\n",
        "        continue\n",
        "    ax[0,0].plot(list(metrics[\"COVID incidence\"].keys()), values, label=fips, color='pink', linewidth=0.2)\n",
        "ax[0,0].set_title(\"COVID incidence\")\n",
        "ax[0,0].axhline(thresholds[0], color='red', linewidth=0.5)  # add threshold line\n",
        "ax[0,0].set_xticks(year_week_COVID)\n",
        "\n",
        "# Plot each county's population density\n",
        "for fips, metrics in data.items():\n",
        "    values = np.array(list(metrics[\"PCIWeightedCOVID\"].values()))\n",
        "    if np.any(values > thresholds[1]):\n",
        "        continue\n",
        "    ax[0,1].plot(list(metrics[\"PCIWeightedCOVID\"].keys()), values, label=fips, color='pink', linewidth=0.2)\n",
        "ax[0,1].set_title(\"PCIWeightedCOVID\")\n",
        "ax[0,1].axhline(thresholds[1], color='red', linewidth=0.5)  # add threshold line\n",
        "ax[0,1].set_xticks(year_week_rest)\n",
        "\n",
        "# Plot each county's black population percentage\n",
        "for fips, metrics in data.items():\n",
        "    values = np.array(list(metrics[\"SCIWeightedCOVID\"].values()))\n",
        "    if np.any(values > thresholds[2]):\n",
        "        continue\n",
        "    ax[1,0].plot(list(metrics[\"SCIWeightedCOVID\"].keys()), values, label=fips, color='pink', linewidth=0.2)\n",
        "ax[1,0].set_title(\"SCIWeightedCOVID\")\n",
        "ax[1,0].axhline(thresholds[2], color='red', linewidth=0.5)  # add threshold line\n",
        "ax[1,0].set_xticks(year_week_rest)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# 假设你想生成一列名为'C'的随机浮点数数据，长度和df的行数相同\n",
        "df['Random'] = np.random.rand(len(df))\n",
        "df.to_csv('D:/Data/COVID/Data/ResultsofWholeUS/FinaldataUSforRNNAddRandomColumn.csv')\n",
        "\n",
        "# 读取CSV文件\n",
        "df = pd.read_csv('D:/Data/COVID/Data/ResultsofWholeUS/FinaldataHIVdiagnoseUSforRNNDeltaWeighted.csv')\n",
        "\n",
        "# 假设你想生成一列名为'C'的随机浮点数数据，长度和df的行数相同\n",
        "df['Random'] = np.random.rand(len(df))\n",
        "df.to_csv('D:/Data/COVID/Data/ResultsofWholeUS/FinaldataHIVdiagnoseUSforRNNDeltaWeightedAddRandomColumn.csv')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}